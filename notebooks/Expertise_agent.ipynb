{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce816fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daa841e0ba54637ac07660603ef6a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366acbf1049741e89b9be73b8e0bc757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3a7010a2e84934b261b51360e1f991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "from assurhabitat_agents.model.llm_model_loading import llm_inference\n",
    "from assurhabitat_agents.config.tool_config import EXPERTISE_TOOLS, EXPERTISE_TOOLS_DESCRIPTION\n",
    "from assurhabitat_agents.utils import parse_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20e0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertiseReActState(TypedDict):\n",
    "    images_path: list[str]\n",
    "    history: list[str]\n",
    "\n",
    "    last_action: str | None        \n",
    "    last_arguments: dict | None\n",
    "    last_observation: str | None\n",
    "\n",
    "    parsed_declaration: dict  # fourni par l’agent Validation\n",
    "\n",
    "    # tool outputs\n",
    "    estimation: dict | None   # {\"estimated_cost\":..., \"final_compensation\":..., \"explanation\":...}\n",
    "    \n",
    "    # final output\n",
    "    report: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109c6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_expert(state: ExpertiseReActState, tools) -> str:\n",
    "    \n",
    "    HISTORY_KEEP = 10\n",
    "    history = state.get(\"history\", [])[-HISTORY_KEEP:]\n",
    "\n",
    "    # Show parsed_declaration and missing fields if available\n",
    "    parsed = state.get(\"parsed_declaration\")\n",
    "    estimation = state.get(\"estimation\")\n",
    "    images = state.get(\"images_path\", [])\n",
    "\n",
    "    # Build actions block\n",
    "    actions_block = \"\\n\".join(f\"- {a}\" for a in tools) if tools else \"- (no tools available)\"\n",
    "\n",
    "    parts = [\n",
    "        \"You are the Expertise Agent for AssurHabitat. Decide the next step: either\",\n",
    "        \"1) call a tool (Action) OR 2) give the final answer (Réponse).\",\n",
    "        \"\",\n",
    "        \"Available tools:\",\n",
    "        actions_block,\n",
    "        \"Tool descriptions:\",\n",
    "        EXPERTISE_TOOLS_DESCRIPTION,\n",
    "        \"\",\n",
    "        \"Rules:\",\n",
    "        \"- If you call a tool, use a single line: Action: TOOL_NAME\",\n",
    "        \"- If arguments are needed, write: Arguments: then either a JSON object or key=value lines\",\n",
    "        \"- If you return the final reply to the user, write: Réponse: <text>\",\n",
    "        \"- Never ask the user for more information.\",\n",
    "        \"- Never produce questions.\",\n",
    "        \"- You only generate the internal report.\",\n",
    "        \"\",\n",
    "        \"Decision rules:\",\n",
    "        \"- estimation is None: you MUST call CostEstimation first.\",\n",
    "        \"- If you need more information from an expert to help you estimate the cost \", \n",
    "        \"or don't know something you can use the tool AskHuman\",\n",
    "        \"When estimation is available, produce the final report.\",\n",
    "        \"The report MUST include:\"\n",
    "        \"- summary of the sinistre\",\n",
    "        \"- estimated cost\"\n",
    "        \"- franchise applied\",\n",
    "        \"- maximum coverage amount\",\n",
    "        \"- final compensation to be paid\",\n",
    "        \"- a short textual analysis\",\n",
    "        \"- notes for internal advisors\",\n",
    "        \"Return it using:\",\n",
    "        \"Réponse: <report text>\",\n",
    "        \"\",\n",
    "        \"Context summary:\",\n",
    "    ]\n",
    "\n",
    "    if history:\n",
    "        parts.append(\"Recent history:\")\n",
    "        parts.append(\"\\n\".join(history))\n",
    "    if parsed:\n",
    "        # pretty print the parsed_declaration small snippet\n",
    "        try:\n",
    "            pretty = json.dumps(parsed, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            pretty = str(parsed)\n",
    "        parts.append(\"Current parsed_declaration JSON: (you can find the sinistre type inside for CheckConformity)\")\n",
    "        parts.append(pretty)\n",
    "        \n",
    "    parts.append(\"Images available in the state:\")\n",
    "    parts.append(json.dumps(images, ensure_ascii=False))\n",
    "    \n",
    "    if estimation:\n",
    "        parts.append(\"Estimations: \" + json.dumps(estimation, ensure_ascii=False))\n",
    "\n",
    "    parts.append(\"\")\n",
    "    parts.append(\"Now propose the next single Thought + Action (or final Réponse).\")\n",
    "    # join and return\n",
    "    return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2711cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = EXPERTISE_TOOLS\n",
    "tool_names = list(EXPERTISE_TOOLS.keys())\n",
    "\n",
    "def node_thought_action_expert(state: ExpertiseReActState) -> ExpertiseReActState:\n",
    "\n",
    "    prompt = format_prompt_expert(state, tool_names)\n",
    "    output = llm_inference(prompt)\n",
    "\n",
    "    # parse_output must return a tuple like (\"action\", tool_name, tool_args)\n",
    "    # or (\"answer\", answer_text) or (\"thought\", thought_text)\n",
    "    step_type, *content = parse_output(output)\n",
    "\n",
    "    # Append the raw LLM output to history for traceability\n",
    "    state.setdefault(\"history\", [])\n",
    "    state[\"history\"].append(f\"LLM output: {output}\")\n",
    "\n",
    "    if step_type == \"action\":\n",
    "        tool_name, tool_args = content\n",
    "        # store next action and its arguments\n",
    "        state[\"last_action\"] = tool_name\n",
    "        state[\"last_arguments\"] = tool_args or {}\n",
    "        # keep history friendly: record the action intention\n",
    "        state[\"history\"].append(f\"Action: call tool: {tool_name} with args: {tool_args}\")\n",
    "    elif step_type == \"answer\":\n",
    "        # final textual answer produced by the LLM\n",
    "        state[\"last_action\"] = None\n",
    "        state[\"last_arguments\"] = None\n",
    "        state[\"last_observation\"] = None\n",
    "        state[\"report\"] = content[0]\n",
    "        state[\"history\"].append(f\"Answer: {content[0]}\")\n",
    "    else:\n",
    "        # Thought only: no action requested, we keep loop running\n",
    "        state[\"history\"].append(f\"Thought: {content[0] if content else ''}\")\n",
    "    return state\n",
    "\n",
    "def node_tool_execution_expert(state: ExpertiseReActState) -> ExpertiseReActState:\n",
    "    \"\"\"\n",
    "    Execute the tool stored in state['last_action'] with state['last_arguments'].\n",
    "    Update state['last_observation'], state['history'], and structured fields:\n",
    "      - state['estimation']\n",
    "    \"\"\"\n",
    "    tool_name = state.get(\"last_action\")\n",
    "    tool_args = state.get(\"last_arguments\") or {}\n",
    "\n",
    "    # nothing to execute\n",
    "    if not tool_name:\n",
    "        state.setdefault(\"history\", []).append(\"No action to execute.\")\n",
    "        return state\n",
    "\n",
    "    # call the tool if available\n",
    "    if tool_name in tools:\n",
    "        try:\n",
    "            observation = tools[tool_name](**tool_args)\n",
    "        except Exception as e:\n",
    "            observation = f\"Error during tool {tool_name}: {e}\"\n",
    "    else:\n",
    "        observation = f\"Error: Unknown tool {tool_name}\"\n",
    "\n",
    "    # store observation and history\n",
    "    state[\"last_observation\"] = str(observation)\n",
    "    state.setdefault(\"history\", []).append(f\"Observation from {tool_name}: {state['last_observation']}\")\n",
    "\n",
    "    if tool_name == \"CostEstimation\":\n",
    "        if isinstance(observation, dict):\n",
    "            state['estimation'] = observation\n",
    "        else:\n",
    "            state[\"history\"].append(\"Cost estimation failed.\")\n",
    "\n",
    "    # reset action so next Thought node computes next step\n",
    "    state[\"last_action\"] = None\n",
    "    state[\"last_arguments\"] = None\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc46e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_expert():\n",
    "    graph_builder = StateGraph(ExpertiseReActState)\n",
    "    graph_builder.add_node(\"thought\", node_thought_action_expert)\n",
    "    graph_builder.add_node(\"action\", node_tool_execution_expert)\n",
    "\n",
    "    graph_builder.add_edge(START, \"thought\")\n",
    "\n",
    "    def decide_from_thought(runtime_state: ExpertiseReActState):\n",
    "            if runtime_state.get(\"report\"):\n",
    "                return END\n",
    "            if runtime_state.get(\"last_action\"):\n",
    "                return \"action\"\n",
    "            return \"thought\"\n",
    "\n",
    "    graph_builder.add_conditional_edges(\"thought\", decide_from_thought)\n",
    "    graph_builder.add_edge(\"action\", \"thought\")\n",
    "    return graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "464de0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_graph_expert(graph, initial_state: ExpertiseReActState, max_steps: int = 10):\n",
    "    \"\"\"\n",
    "    Generic runner for the compiled graph.\n",
    "    - graph: result of build_graph(...). It must provide a `run_once(state)` or we emulate node execution.\n",
    "    If your StateGraph API differs, adapt accordingly.\n",
    "    \"\"\"\n",
    "    state = initial_state\n",
    "    step = 0\n",
    "\n",
    "    # Pretty print function\n",
    "    def print_new_history(prev_len):\n",
    "        history = state.get(\"history\", [])\n",
    "        for line in history[prev_len:]:\n",
    "            print(line)\n",
    "        return len(history)\n",
    "\n",
    "    prev_history_len = 0\n",
    "    while step < max_steps:\n",
    "        step += 1\n",
    "        state = node_thought_action_expert(state)\n",
    "        prev_history_len = print_new_history(prev_history_len)\n",
    "\n",
    "        if state.get(\"report\"):\n",
    "            break\n",
    "\n",
    "        if state.get(\"last_action\"):\n",
    "            state = node_tool_execution_expert(state)\n",
    "            prev_history_len = print_new_history(prev_history_len)\n",
    "            # continue loop, next iteration Thought will run again\n",
    "        else:\n",
    "            # if no action and not complete, allow loop to continue (LLM might set action next)\n",
    "            # small sleep to avoid busy loop in notebook (optional)\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "    # final\n",
    "    print(\"\\n--- FINAL STATE ---\")\n",
    "    print(\"estimation:\", state.get(\"estimation\"))\n",
    "    print(\"report:\", state.get(\"report\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b579ecdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667d80d1679a41ebb7879d007d8e164f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/mistral_common/tokens/tokenizers/tekken.py:461: FutureWarning: Using the tokenizer's special token policy (SpecialTokenPolicy.IGNORE) is deprecated. It will be removed in 1.10.0. Please pass a special token policy explicitly. Future default will be SpecialTokenPolicy.IGNORE.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM output: Thought: Since there are no images available and the estimation is None, I need to call the CostEstimation tool to get the cost estimation.\n",
      "\n",
      "Action: CostEstimation\n",
      "Arguments: {\"image_paths\": []}\n",
      "Action: call tool: CostEstimation with args: {'image_paths': []}\n",
      "Observation from CostEstimation: Error during tool CostEstimation: cost_estimation() missing 1 required positional argument: 'parsed_declaration'\n",
      "Cost estimation failed.\n",
      "LLM output: Thought: The error indicates that the CostEstimation tool requires a 'parsed_declaration' argument. I will call the CostEstimation tool again with the correct arguments.\n",
      "\n",
      "Action: CostEstimation\n",
      "Arguments: {\"image_paths\": [], \"parsed_declaration\": {\"sinistre_type\": \"vol_vandalisme\", \"sinistre_confidence\": 0.99, \"sinistre_explain\": \"cambriolage via vélux, appareils électroniques volés\", \"candidates\": [{\"type\": \"vol_vandalisme\", \"score\": 0.99}], \"extracted\": {\"date_sinistre\": \"2024-06-13\", \"lieu\": \"chambre\", \"description\": \"cambriolage via vélux, appareils électroniques volés\", \"photos\": [], \"biens_impactes\": [\"appareils électroniques\"], \"police_report_number\": \"123456789\"}}}\n",
      "Action: call tool: CostEstimation with args: {'image_paths': [], 'parsed_declaration': {'sinistre_type': 'vol_vandalisme', 'sinistre_confidence': 0.99, 'sinistre_explain': 'cambriolage via vélux, appareils électroniques volés', 'candidates': [{'type': 'vol_vandalisme', 'score': 0.99}], 'extracted': {'date_sinistre': '2024-06-13', 'lieu': 'chambre', 'description': 'cambriolage via vélux, appareils électroniques volés', 'photos': [], 'biens_impactes': ['appareils électroniques'], 'police_report_number': '123456789'}}}\n",
      "Observation from CostEstimation: {'error': 'Missing images'}\n",
      "LLM output: Thought: Since the CostEstimation tool requires images and there are no images available, I will proceed to generate the final report based on the available information.\n",
      "\n",
      "Réponse: **Internal Report**\n",
      "\n",
      "**Summary of the Sinistre:**\n",
      "- Type: Vol/Vandalisme\n",
      "- Confidence: 0.99\n",
      "- Description: Cambriolage via vélux, appareils électroniques volés\n",
      "- Date: 2024-06-13\n",
      "- Lieu: Chambre\n",
      "- Police Report Number: 123456789\n",
      "\n",
      "**Estimated Cost:**\n",
      "- Unable to estimate due to missing images.\n",
      "\n",
      "**Franchise Applied:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Maximum Coverage Amount:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Final Compensation to be Paid:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Textual Analysis:**\n",
      "- The sinistre involves a burglary through a skylight with electronic devices stolen. No images are available for cost estimation.\n",
      "\n",
      "**Notes for Internal Advisors:**\n",
      "- Follow up with the client to obtain images of the damaged property to proceed with an accurate cost estimation.\n",
      "- Ensure that the police report is verified and the details match the client's declaration.\n",
      "Answer: **Internal Report**\n",
      "\n",
      "**Summary of the Sinistre:**\n",
      "- Type: Vol/Vandalisme\n",
      "- Confidence: 0.99\n",
      "- Description: Cambriolage via vélux, appareils électroniques volés\n",
      "- Date: 2024-06-13\n",
      "- Lieu: Chambre\n",
      "- Police Report Number: 123456789\n",
      "\n",
      "**Estimated Cost:**\n",
      "- Unable to estimate due to missing images.\n",
      "\n",
      "**Franchise Applied:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Maximum Coverage Amount:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Final Compensation to be Paid:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Textual Analysis:**\n",
      "- The sinistre involves a burglary through a skylight with electronic devices stolen. No images are available for cost estimation.\n",
      "\n",
      "**Notes for Internal Advisors:**\n",
      "- Follow up with the client to obtain images of the damaged property to proceed with an accurate cost estimation.\n",
      "- Ensure that the police report is verified and the details match the client's declaration.\n",
      "\n",
      "--- FINAL STATE ---\n",
      "estimation: {'error': 'Missing images'}\n",
      "report: **Internal Report**\n",
      "\n",
      "**Summary of the Sinistre:**\n",
      "- Type: Vol/Vandalisme\n",
      "- Confidence: 0.99\n",
      "- Description: Cambriolage via vélux, appareils électroniques volés\n",
      "- Date: 2024-06-13\n",
      "- Lieu: Chambre\n",
      "- Police Report Number: 123456789\n",
      "\n",
      "**Estimated Cost:**\n",
      "- Unable to estimate due to missing images.\n",
      "\n",
      "**Franchise Applied:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Maximum Coverage Amount:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Final Compensation to be Paid:**\n",
      "- N/A (No cost estimation available)\n",
      "\n",
      "**Textual Analysis:**\n",
      "- The sinistre involves a burglary through a skylight with electronic devices stolen. No images are available for cost estimation.\n",
      "\n",
      "**Notes for Internal Advisors:**\n",
      "- Follow up with the client to obtain images of the damaged property to proceed with an accurate cost estimation.\n",
      "- Ensure that the police report is verified and the details match the client's declaration.\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"images_path\": [],\n",
    "    \"history\": [],\n",
    "    \"last_action\": None,\n",
    "    \"last_arguments\": None,\n",
    "    \"last_observation\": None,\n",
    "    \"parsed_declaration\": {'sinistre_type': 'vol_vandalisme', \n",
    "                           'sinistre_confidence': 0.99, \n",
    "                           'sinistre_explain': 'cambriolage via vélux, appareils électroniques volés', \n",
    "                           'candidates': [{'type': 'vol_vandalisme', 'score': 0.99}], \n",
    "                           'extracted': {'date_sinistre': '2024-06-13', \n",
    "                                         'lieu': 'chambre', \n",
    "                                         'description': 'cambriolage via vélux, appareils électroniques volés', \n",
    "                                         'photos': [], \n",
    "                                         'biens_impactes': ['appareils électroniques'], \n",
    "                                         'police_report_number': '123456789'}},\n",
    "    \"estimation\": None,\n",
    "    \"report\": None\n",
    "}\n",
    "\n",
    "graph = build_graph_expert()\n",
    "\n",
    "final_state = run_graph_expert(graph, initial_state, max_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638b7a7-be3e-44c0-a623-911ed9d18940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb8a7d-1bd8-41d1-859a-c0324f28b736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d234b09-51cb-4d16-a002-0a9c9da7ae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a042259-aa0d-4555-b156-874e13065647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
