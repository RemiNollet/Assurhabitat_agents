{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce816fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "from assurhabitat_agents.model.llm_model_loading import llm_inference\n",
    "from assurhabitat_agents.config.tool_config import EXPERTISE_TOOLS, EXPERTISE_TOOLS_DESCRIPTION\n",
    "from assurhabitat_agents.utils import parse_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e0e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertiseReActState(TypedDict):\n",
    "    images_path: list[str]\n",
    "    history: list[str]\n",
    "\n",
    "    last_action: str | None        \n",
    "    last_arguments: dict | None\n",
    "    last_observation: str | None\n",
    "\n",
    "    parsed_declaration: dict  # fourni par l’agent Validation\n",
    "\n",
    "    # tool outputs\n",
    "    estimation: dict | None   # {\"estimated_cost\":..., \"final_compensation\":..., \"explanation\":...}\n",
    "    \n",
    "    # final output\n",
    "    report: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_expert(state: ExpertiseReActState, tools) -> str:\n",
    "    \n",
    "    HISTORY_KEEP = 10\n",
    "    history = state.get(\"history\", [])[-HISTORY_KEEP:]\n",
    "\n",
    "    # Show parsed_declaration and missing fields if available\n",
    "    parsed = state.get(\"parsed_declaration\")\n",
    "    estimation = state.get(\"estimation\")\n",
    "    images = state.get(\"images_path\", [])\n",
    "\n",
    "    # Build actions block\n",
    "    actions_block = \"\\n\".join(f\"- {a}\" for a in tools) if tools else \"- (no tools available)\"\n",
    "\n",
    "    parts = [\n",
    "        \"You are the Expertise Agent for AssurHabitat. Decide the next step: either\",\n",
    "        \"1) call a tool (Action) OR 2) give the final answer (Réponse).\",\n",
    "        \"\",\n",
    "        \"Available tools:\",\n",
    "        actions_block,\n",
    "        \"Tool descriptions:\",\n",
    "        EXPERTISE_TOOLS_DESCRIPTION,\n",
    "        \"\",\n",
    "        \"Rules:\",\n",
    "        \"- If you call a tool, use a single line: Action: TOOL_NAME\",\n",
    "        \"- If arguments are needed, write: Arguments: then either a JSON object or key=value lines\",\n",
    "        \"- If you return the final reply to the user, write: Réponse: <text>\",\n",
    "        \"- Never ask the user for more information.\",\n",
    "        \"- Never produce questions.\",\n",
    "        \"- You only generate the internal report.\",\n",
    "        \"\",\n",
    "        \"Decision rules:\",\n",
    "        \"- estimation is None: you MUST call CostEstimation first.\",\n",
    "        \"When estimation is available, produce the final report.\",\n",
    "        \"The report MUST include:\"\n",
    "        \"- summary of the sinistre\",\n",
    "        \"- estimated cost\"\n",
    "        \"- franchise applied\",\n",
    "        \"- maximum coverage amount\",\n",
    "        \"- final compensation to be paid\",\n",
    "        \"- a short textual analysis\",\n",
    "        \"- notes for internal advisors\",\n",
    "        \"Return it using:\",\n",
    "        \"Réponse: <report text>\",\n",
    "        \"\",\n",
    "        \"Context summary:\",\n",
    "    ]\n",
    "\n",
    "    if history:\n",
    "        parts.append(\"Recent history:\")\n",
    "        parts.append(\"\\n\".join(history))\n",
    "    if parsed:\n",
    "        # pretty print the parsed_declaration small snippet\n",
    "        try:\n",
    "            pretty = json.dumps(parsed, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            pretty = str(parsed)\n",
    "        parts.append(\"Current parsed_declaration JSON: (you can find the sinistre type inside for CheckConformity)\")\n",
    "        parts.append(pretty)\n",
    "        \n",
    "    parts.append(\"Images available in the state:\")\n",
    "    parts.append(json.dumps(images, ensure_ascii=False))\n",
    "    \n",
    "    if estimation:\n",
    "        parts.append(\"Estimations: \" + json.dumps(estimation, ensure_ascii=False))\n",
    "\n",
    "    parts.append(\"\")\n",
    "    parts.append(\"Now propose the next single Thought + Action (or final Réponse).\")\n",
    "    # join and return\n",
    "    return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = EXPERTISE_TOOLS\n",
    "tool_names = list(EXPERTISE_TOOLS.keys())\n",
    "\n",
    "def node_thought_action_expert(state: ExpertiseReActState) -> ExpertiseReActState:\n",
    "\n",
    "    prompt = format_prompt_expert(state, tool_names)\n",
    "    output = llm_inference(prompt)\n",
    "\n",
    "    # parse_output must return a tuple like (\"action\", tool_name, tool_args)\n",
    "    # or (\"answer\", answer_text) or (\"thought\", thought_text)\n",
    "    step_type, *content = parse_output(output)\n",
    "\n",
    "    # Append the raw LLM output to history for traceability\n",
    "    state.setdefault(\"history\", [])\n",
    "    state[\"history\"].append(f\"LLM output: {output}\")\n",
    "\n",
    "    if step_type == \"action\":\n",
    "        tool_name, tool_args = content\n",
    "        # store next action and its arguments\n",
    "        state[\"last_action\"] = tool_name\n",
    "        state[\"last_arguments\"] = tool_args or {}\n",
    "        # keep history friendly: record the action intention\n",
    "        state[\"history\"].append(f\"Action: call tool: {tool_name} with args: {tool_args}\")\n",
    "    elif step_type == \"answer\":\n",
    "        # final textual answer produced by the LLM\n",
    "        state[\"last_action\"] = None\n",
    "        state[\"last_arguments\"] = None\n",
    "        state[\"last_observation\"] = None\n",
    "        state[\"report\"] = content[0]\n",
    "        state[\"history\"].append(f\"Answer: {content[0]}\")\n",
    "    else:\n",
    "        # Thought only: no action requested, we keep loop running\n",
    "        state[\"history\"].append(f\"Thought: {content[0] if content else ''}\")\n",
    "    return state\n",
    "\n",
    "def node_tool_execution_expert(state: ExpertiseReActState) -> ExpertiseReActState:\n",
    "    \"\"\"\n",
    "    Execute the tool stored in state['last_action'] with state['last_arguments'].\n",
    "    Update state['last_observation'], state['history'], and structured fields:\n",
    "      - state['estimation']\n",
    "    \"\"\"\n",
    "    tool_name = state.get(\"last_action\")\n",
    "    tool_args = state.get(\"last_arguments\") or {}\n",
    "\n",
    "    # nothing to execute\n",
    "    if not tool_name:\n",
    "        state.setdefault(\"history\", []).append(\"No action to execute.\")\n",
    "        return state\n",
    "\n",
    "    # call the tool if available\n",
    "    if tool_name in EXPERTISE_TOOLS:\n",
    "        try:\n",
    "            observation = EXPERTISE_TOOLS[tool_name](**tool_args)\n",
    "        except Exception as e:\n",
    "            observation = f\"Error during tool {tool_name}: {e}\"\n",
    "    else:\n",
    "        observation = f\"Error: Unknown tool {tool_name}\"\n",
    "\n",
    "    # store observation and history\n",
    "    state[\"last_observation\"] = str(observation)\n",
    "    state.setdefault(\"history\", []).append(f\"Observation from {tool_name}: {state['last_observation']}\")\n",
    "\n",
    "    if tool_name == \"CostEstimation\":\n",
    "        if isinstance(observation, dict):\n",
    "            state['estimation'] = observation\n",
    "        else:\n",
    "            state[\"history\"].append(\"Cost estimation failed.\")\n",
    "\n",
    "    # reset action so next Thought node computes next step\n",
    "    state[\"last_action\"] = None\n",
    "    state[\"last_arguments\"] = None\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_expert():\n",
    "    graph_builder = StateGraph(ExpertiseReActState)\n",
    "    graph_builder.add_node(\"thought\", node_thought_action_expert)\n",
    "    graph_builder.add_node(\"action\", node_tool_execution_expert)\n",
    "\n",
    "    graph_builder.add_edge(START, \"thought\")\n",
    "\n",
    "    def decide_from_thought(runtime_state: ExpertiseReActState):\n",
    "            if runtime_state.get(\"report\"):\n",
    "                return END\n",
    "            if runtime_state.get(\"last_action\"):\n",
    "                return \"action\"\n",
    "            return \"thought\"\n",
    "\n",
    "    graph_builder.add_conditional_edges(\"thought\", decide_from_thought)\n",
    "    graph_builder.add_edge(\"action\", \"thought\")\n",
    "    return graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464de0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_graph_expert(graph, initial_state: ExpertiseReActState, max_steps: int = 10):\n",
    "    \"\"\"\n",
    "    Generic runner for the compiled graph.\n",
    "    - graph: result of build_graph(...). It must provide a `run_once(state)` or we emulate node execution.\n",
    "    If your StateGraph API differs, adapt accordingly.\n",
    "    \"\"\"\n",
    "    state = initial_state\n",
    "    step = 0\n",
    "\n",
    "    # Pretty print function\n",
    "    def print_new_history(prev_len):\n",
    "        history = state.get(\"history\", [])\n",
    "        for line in history[prev_len:]:\n",
    "            print(line)\n",
    "        return len(history)\n",
    "\n",
    "    prev_history_len = 0\n",
    "    while step < max_steps:\n",
    "        step += 1\n",
    "        state = node_thought_action_expert(state)\n",
    "        prev_history_len = print_new_history(prev_history_len)\n",
    "\n",
    "        if state.get(\"report\"):\n",
    "            break\n",
    "\n",
    "        if state.get(\"last_action\"):\n",
    "            state = node_tool_execution_expert(state)\n",
    "            prev_history_len = print_new_history(prev_history_len)\n",
    "            # continue loop, next iteration Thought will run again\n",
    "        else:\n",
    "            # if no action and not complete, allow loop to continue (LLM might set action next)\n",
    "            # small sleep to avoid busy loop in notebook (optional)\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "    # final\n",
    "    print(\"\\n--- FINAL STATE ---\")\n",
    "    print(\"estimation:\", state.get(\"estimation\"))\n",
    "    print(\"report:\", state.get(\"report\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"images_path\": [],\n",
    "    \"history\": [],\n",
    "    \"last_action\": None,\n",
    "    \"last_arguments\": None,\n",
    "    \"last_observation\": None,\n",
    "    \"parsed_declaration\": {'sinistre_type': 'vol_vandalisme', \n",
    "                           'sinistre_confidence': 0.99, \n",
    "                           'sinistre_explain': 'cambriolage via vélux, appareils électroniques volés', \n",
    "                           'candidates': [{'type': 'vol_vandalisme', 'score': 0.99}], \n",
    "                           'extracted': {'date_sinistre': '2024-06-13', \n",
    "                                         'lieu': 'chambre', \n",
    "                                         'description': 'cambriolage via vélux, appareils électroniques volés', \n",
    "                                         'photos': [], \n",
    "                                         'biens_impactes': ['appareils électroniques'], \n",
    "                                         'police_report_number': '123456789'}},\n",
    "    \"estimation\": None,\n",
    "    \"report\": None\n",
    "}\n",
    "\n",
    "graph = build_graph_expert()\n",
    "\n",
    "final_state = run_graph_expert(graph, initial_state, max_steps=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
