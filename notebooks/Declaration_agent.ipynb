{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d4579f",
   "metadata": {},
   "source": [
    "# Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c28663",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install curl unzip\n",
    "!curl -d -O https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/projects/00ba97/Agentic+Chatbot+Assurance+Habitation+-+Processus.md data/\n",
    "!curl -d -O https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/projects/00ba97/Agentic+Chatbot+Assurance+Habitation+-+Garanties.md data/\n",
    "!curl -d -O https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/projects/00ba97/attachments.zip data/\n",
    "!unzip data/attachments.zip data/\n",
    "!rm data/attachments.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df9a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "from typing import Tuple, Dict, Any, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "from assurhabitat_agents.llm.model_loading import llm_inference\n",
    "from assurhabitat_agents.config.config import TOOLS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843294df",
   "metadata": {},
   "source": [
    "# Declaration agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6753fa",
   "metadata": {},
   "source": [
    "## Tools\n",
    "2. parse_declaration\n",
    "3. verify_completeness\n",
    "4. ask_human\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeclarationReActState(TypedDict):\n",
    "    question: str  # La question initiale de l'utilisateur\n",
    "    history: list[str]  # L'historique des échanges (Thought, Action, Observation)\n",
    "    last_action: str | None  # Le nom de l'outil à appeler (si applicable)\n",
    "    last_arguments: dict | None  # Les arguments à passer à l'outil\n",
    "    last_observation: str | None  # Le résultat de l'outil appelé\n",
    "    is_complete: bool | None  # La réponse finale\n",
    "    parsed_declaration: dict | None # Stockage json de la declaration parser par le tool\n",
    "    missing: list[str] | None # champs manquant dans la declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e847ea0",
   "metadata": {},
   "source": [
    "## Nodes\n",
    "1. thought\n",
    "2. execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24bf7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(state: DeclarationReActState, tools) -> str:\n",
    "    \"\"\"\n",
    "    Build a concise prompt for the ReAct LLM using the whole state.\n",
    "    - state: the DeclarationReActState dict (contains history, parsed_declaration, missing, question, etc.)\n",
    "    - actions: list of available tool names with short descriptions (e.g. [\"parse_declaration\", \"verify_completeness\", \"ask_human\"])\n",
    "    The function returns a prompt string ready to be sent to the LLM.\n",
    "    \"\"\"\n",
    "    # Keep prompt short: only include last few history entries\n",
    "    HISTORY_KEEP = 10\n",
    "    history = state.get(\"history\", [])[-HISTORY_KEEP:]\n",
    "\n",
    "    # Show parsed_declaration and missing fields if available\n",
    "    parsed = state.get(\"parsed_declaration\")\n",
    "    missing = state.get(\"missing\", [])\n",
    "\n",
    "    # Build actions block\n",
    "    actions_block = \"\\n\".join(f\"- {a}\" for a in tools) if tools else \"- (no tools available)\"\n",
    "\n",
    "    parts = [\n",
    "        \"You are the Declaration Agent for AssurHabitat. Decide the next step: either\",\n",
    "        \"1) call a tool (Action) OR 2) give the final answer (Réponse).\",\n",
    "        \"\",\n",
    "        \"Available tools:\",\n",
    "        actions_block,\n",
    "        \"\",\n",
    "        \"Rules:\",\n",
    "        \"- If you call a tool, use a single line: Action: TOOL_NAME\",\n",
    "        \"- If arguments are needed, write: Arguments: then either a JSON object or key=value lines\",\n",
    "        \"- If you return the final reply to the user, write: Réponse: <text>\",\n",
    "        \"\",\n",
    "        \"Context summary:\",\n",
    "    ]\n",
    "\n",
    "    if state.get(\"question\"):\n",
    "        parts.append(f\"Original question: {state['question']}\")\n",
    "    if history:\n",
    "        parts.append(\"Recent history:\")\n",
    "        parts.append(\"\\n\".join(history))\n",
    "    if parsed:\n",
    "        # pretty print the parsed_declaration small snippet\n",
    "        try:\n",
    "            pretty = json.dumps(parsed, ensure_ascii=False)\n",
    "        except Exception:\n",
    "            pretty = str(parsed)\n",
    "        parts.append(\"Current parsed_declaration JSON:\")\n",
    "        parts.append(pretty)\n",
    "    if missing:\n",
    "        parts.append(\"Missing fields (need to ask human if required):\")\n",
    "        parts.append(\", \".join(missing))\n",
    "\n",
    "    parts.append(\"\")\n",
    "    parts.append(\"Now propose the next single Thought + Action (or final Réponse).\")\n",
    "    # join and return\n",
    "    return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_output(output: str) -> Tuple[str, Any, Any]:\n",
    "    \"\"\"\n",
    "    Parse LLM output and return a tuple:\n",
    "    - (\"action\", tool_name, tool_args_dict)\n",
    "    - (\"answer\", answer_text, None)\n",
    "    - (\"thought\", thought_text, None)\n",
    "\n",
    "    This parser is tolerant:\n",
    "    - accepts \"Action: TOOLNAME\" on a line\n",
    "    - accepts arguments as either JSON after \"Arguments:\" OR key=value lines\n",
    "    - if parsing fails for args, returns them as raw string under {\"raw\": \"...\"}\n",
    "    \"\"\"\n",
    "    text = output.strip()\n",
    "\n",
    "    # Try to find an \"Action:\" line (match up to end-of-line, non-greedy)\n",
    "    m_action = re.search(r\"(?mi)^Action:\\s*(?P<tool>[^\\n\\r]+)\", text)\n",
    "    m_args = re.search(r\"(?mi)^Arguments:\\s*(?P<args>[\\s\\S]+)$\", text)  # capture until string end\n",
    "\n",
    "    # If action present, parse args if any\n",
    "    if m_action:\n",
    "        tool_name = m_action.group(\"tool\").strip()\n",
    "        tool_args = {}\n",
    "\n",
    "        if m_args:\n",
    "            raw_args = m_args.group(\"args\").strip()\n",
    "            # Try JSON first\n",
    "            try:\n",
    "                parsed = json.loads(raw_args)\n",
    "                if isinstance(parsed, dict):\n",
    "                    tool_args = parsed\n",
    "                else:\n",
    "                    tool_args = {\"raw\": parsed}\n",
    "            except Exception:\n",
    "                # Fallback: parse key=value lines\n",
    "                lines = [l.strip() for l in raw_args.splitlines() if l.strip()]\n",
    "                kv = {}\n",
    "                for line in lines:\n",
    "                    # accept \"key = value\" or \"key=value\"\n",
    "                    m_kv = re.match(r\"^\\s*([^=]+?)\\s*=\\s*(.+)$\", line)\n",
    "                    if m_kv:\n",
    "                        key = m_kv.group(1).strip()\n",
    "                        val = m_kv.group(2).strip()\n",
    "                        # try to interpret JSON value (numbers, lists, etc.)\n",
    "                        try:\n",
    "                            val_parsed = json.loads(val)\n",
    "                        except Exception:\n",
    "                            val_parsed = val\n",
    "                        kv[key] = val_parsed\n",
    "                    else:\n",
    "                        # can't parse line -> keep raw under a list\n",
    "                        kv.setdefault(\"_raw_lines\", []).append(line)\n",
    "                tool_args = kv if kv else {\"raw\": raw_args}\n",
    "\n",
    "        return (\"action\", tool_name, tool_args)\n",
    "\n",
    "    # If there's a \"Réponse:\" or \"Answer:\" line, treat as final answer\n",
    "    m_answer = re.search(r\"(?mi)^(Réponse|Answer):\\s*(?P<ans>[\\s\\S]+)$\", text)\n",
    "    if m_answer:\n",
    "        return (\"answer\", m_answer.group(\"ans\").strip(), None)\n",
    "\n",
    "    # Try to parse JSON directly as answer/action\n",
    "    try:\n",
    "        j = json.loads(text)\n",
    "        if isinstance(j, dict):\n",
    "            # if dict contains action key, map to action\n",
    "            if \"action\" in j:\n",
    "                return (\"action\", j.get(\"action\"), j.get(\"args\", {}))\n",
    "            if \"answer\" in j:\n",
    "                return (\"answer\", j.get(\"answer\"), None)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # otherwise fallback to thought\n",
    "    return (\"thought\", text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a181b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = TOOLS\n",
    "tool_names = list(TOOLS.keys())\n",
    "\n",
    "def node_thought_action(state: DeclarationReActState) -> DeclarationReActState:\n",
    "    \"\"\"\n",
    "    Node that produces the next Thought/Action/Answer using the LLM.\n",
    "    It fills last_action/last_arguments when the LLM asks to call a tool,\n",
    "    or writes the final answer when the LLM produces an 'answer'.\n",
    "    \"\"\"\n",
    "    # Build the prompt using the state's history and some structured context\n",
    "    # It's helpful to include parsed_declaration and missing fields in the prompt so the LLM\n",
    "    # can reason clearly about the next step.\n",
    "    prompt = format_prompt(state, tool_names)\n",
    "    output = llm_inference(prompt)\n",
    "\n",
    "    # parse_output must return a tuple like (\"action\", tool_name, tool_args)\n",
    "    # or (\"answer\", answer_text) or (\"thought\", thought_text)\n",
    "    step_type, *content = parse_output(output)\n",
    "\n",
    "    # Append the raw LLM output to history for traceability\n",
    "    state.setdefault(\"history\", [])\n",
    "    state[\"history\"].append(f\"LLM output: {output}\")\n",
    "\n",
    "    if step_type == \"action\":\n",
    "        tool_name, tool_args = content\n",
    "        # store next action and its arguments\n",
    "        state[\"last_action\"] = tool_name\n",
    "        state[\"last_arguments\"] = tool_args or {}\n",
    "        # keep history friendly: record the action intention\n",
    "        state[\"history\"].append(f\"Action: call tool: {tool_name} with args: {tool_args}\")\n",
    "    elif step_type == \"answer\":\n",
    "        # final textual answer produced by the LLM\n",
    "        state[\"is_complete\"] = True\n",
    "        state[\"last_action\"] = None\n",
    "        state[\"last_arguments\"] = None\n",
    "        state[\"last_observation\"] = None\n",
    "        state[\"history\"].append(f\"Answer: {content[0]}\")\n",
    "    else:\n",
    "        # Thought only: no action requested, we keep loop running\n",
    "        state[\"history\"].append(f\"Thought: {content[0] if content else ''}\")\n",
    "    return state\n",
    "\n",
    "def node_tool_execution(state: DeclarationReActState) -> DeclarationReActState:\n",
    "    \"\"\"\n",
    "    Execute the tool stored in state['last_action'] with state['last_arguments'].\n",
    "    Update state['last_observation'], state['history'], and structured fields:\n",
    "      - state['parsed_declaration']\n",
    "      - state['is_complete'], state['missing'] via verify_completeness(parsed_declaration)\n",
    "    Behavior for ask_human:\n",
    "      - If parse_declaration tool exists, we call it with a combined raw input that\n",
    "        contains the old parsed JSON and the new human reply so the LLM can merge them.\n",
    "      - Otherwise, a simple heuristic fills the first missing field with the reply.\n",
    "    \"\"\"\n",
    "    tool_name = state.get(\"last_action\")\n",
    "    tool_args = state.get(\"last_arguments\") or {}\n",
    "\n",
    "    # nothing to execute\n",
    "    if not tool_name:\n",
    "        state.setdefault(\"history\", []).append(\"No action to execute.\")\n",
    "        return state\n",
    "\n",
    "    # call the tool if available\n",
    "    if tool_name in TOOLS:\n",
    "        try:\n",
    "            observation = TOOLS[tool_name](**tool_args)\n",
    "        except Exception as e:\n",
    "            observation = f\"Error during tool {tool_name}: {e}\"\n",
    "    else:\n",
    "        observation = f\"Error: Unknown tool {tool_name}\"\n",
    "\n",
    "    # store observation and history\n",
    "    state[\"last_observation\"] = str(observation)\n",
    "    state.setdefault(\"history\", []).append(f\"Observation from {tool_name}: {state['last_observation']}\")\n",
    "\n",
    "    if tool_name == \"parse_declaration\":\n",
    "        if isinstance(observation, dict):\n",
    "            # Replace entire parsed_declaration with returned dict\n",
    "            state[\"parsed_declaration\"] = observation\n",
    "\n",
    "            # After parsing, run verify_completeness if available\n",
    "            if \"verify_completeness\" in TOOLS:\n",
    "                try:\n",
    "                    verify_res = TOOLS[\"verify_completeness\"](state[\"parsed_declaration\"])\n",
    "                    if isinstance(verify_res, dict):\n",
    "                        state[\"is_complete\"] = bool(verify_res.get(\"is_complete\", False))\n",
    "                        state[\"missing\"] = verify_res.get(\"missing\", [])\n",
    "                        state[\"history\"].append(f\"Auto-verify result: {verify_res}\")\n",
    "                except Exception as e:\n",
    "                    state[\"history\"].append(f\"Auto-verify failed: {e}\")\n",
    "        else:\n",
    "            state[\"history\"].append(\"parse_declaration returned non-dict observation.\")\n",
    "\n",
    "    # ---------- CASE 2: verify_completeness tool (explicit call) ----------\n",
    "    elif tool_name == \"verify_completeness\":\n",
    "        if isinstance(observation, dict):\n",
    "            state[\"is_complete\"] = bool(observation.get(\"is_complete\", False))\n",
    "            state[\"missing\"] = observation.get(\"missing\", [])\n",
    "        else:\n",
    "            state[\"history\"].append(\"verify_completeness returned unexpected output.\")\n",
    "\n",
    "    # ---------- CASE 3: ask_human tool (human response) ----------\n",
    "    elif tool_name == \"ask_human\":\n",
    "        # observation expected to be the human reply string (or similar)\n",
    "        human_reply = observation if isinstance(observation, str) else str(observation)\n",
    "        state[\"history\"].append(f\"Human replied: {human_reply}\")\n",
    "\n",
    "        # If parse_declaration tool exists, call it with merged input:\n",
    "        # Build combined raw input: include previous parsed_declaration JSON and the new human reply.\n",
    "        if \"parse_declaration\" in TOOLS and isinstance(state.get(\"parsed_declaration\"), dict):\n",
    "            # Convert previous parsed_declaration to compact JSON and instruct the LLM to merge\n",
    "            prev_json = json.dumps(state[\"parsed_declaration\"], ensure_ascii=False)\n",
    "            combined_raw_input = (\n",
    "                \"Existing parsed JSON:\\n\" + prev_json + \"\\n\\n\"\n",
    "                \"New user input (please update the JSON using this new information):\\n\"\n",
    "                + human_reply\n",
    "                + \"\\n\\n\"\n",
    "                \"- If the input contains already a JSON and new information, add the new information to the old JSON and return the new JSON.\"\n",
    "            )\n",
    "            try:\n",
    "                merged_obs = TOOLS[\"parse_declaration\"](combined_raw_input)\n",
    "                # If the parse_declaration returns dict, update parsed_declaration and re-run verify\n",
    "                if isinstance(merged_obs, dict):\n",
    "                    state[\"parsed_declaration\"] = merged_obs\n",
    "\n",
    "                    # call verify_completeness automatically\n",
    "                    if \"verify_completeness\" in TOOLS:\n",
    "                        try:\n",
    "                            verify_res = TOOLS[\"verify_completeness\"](state[\"parsed_declaration\"])\n",
    "                            if isinstance(verify_res, dict):\n",
    "                                state[\"is_complete\"] = bool(verify_res.get(\"is_complete\", False))\n",
    "                                state[\"missing\"] = verify_res.get(\"missing\", [])\n",
    "                                state[\"history\"].append(f\"Auto-verify after human reply: {verify_res}\")\n",
    "                        except Exception as e:\n",
    "                            state[\"history\"].append(f\"Auto-verify failed after human reply: {e}\")\n",
    "\n",
    "                    # Clear asked missing fields or remove those filled by LLM\n",
    "                    # We keep the current 'missing' returned by verify_completeness.\n",
    "                else:\n",
    "                    # If parse_declaration did not return dict, fallback: simple fill\n",
    "                    if state.get(\"missing\"):\n",
    "                        first = state[\"missing\"][0]\n",
    "                        state.setdefault(\"parsed_declaration\", {}).setdefault(\"extracted\", {})[first] = human_reply\n",
    "                        state[\"missing\"] = state.get(\"missing\", [])[1:]\n",
    "                        state[\"history\"].append(f\"Filled {first} with human reply (fallback).\")\n",
    "\n",
    "            except Exception as e:\n",
    "                # on error, fallback to naive update\n",
    "                if state.get(\"missing\"):\n",
    "                    first = state[\"missing\"][0]\n",
    "                    state.setdefault(\"parsed_declaration\", {}).setdefault(\"extracted\", {})[first] = human_reply\n",
    "                    state[\"missing\"] = state.get(\"missing\", [])[1:]\n",
    "                    state[\"history\"].append(f\"Filled {first} with human reply (fallback due to error: {e}).\")\n",
    "        else:\n",
    "            # No parse tool available -> naive fill into first missing field\n",
    "            if state.get(\"missing\"):\n",
    "                first = state[\"missing\"][0]\n",
    "                state.setdefault(\"parsed_declaration\", {}).setdefault(\"extracted\", {})[first] = human_reply\n",
    "                state[\"missing\"] = state.get(\"missing\", [])[1:]\n",
    "                state[\"history\"].append(f\"Filled {first} with human reply (no parse tool).\")\n",
    "\n",
    "    # reset action so next Thought node computes next step\n",
    "    state[\"last_action\"] = None\n",
    "    state[\"last_arguments\"] = None\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8372dfee",
   "metadata": {},
   "source": [
    "## Graph building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e0a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(initial_state: DeclarationReActState):\n",
    "    graph_builder = StateGraph(initial_state)\n",
    "    graph_builder.add_node(\"thought\", node_thought_action)\n",
    "    graph_builder.add_node(\"action\", node_tool_execution)\n",
    "\n",
    "    graph_builder.add_edge(START, \"thought\")\n",
    "\n",
    "    def decide_from_thought(runtime_state: DeclarationReActState):\n",
    "            if runtime_state.get(\"is_complete\"):\n",
    "                return END\n",
    "            if runtime_state.get(\"last_action\"):\n",
    "                return \"action\"\n",
    "            return END\n",
    "\n",
    "    graph_builder.add_conditional_edges(\"thought\", decide_from_thought)\n",
    "    graph_builder.add_edge(\"action\", \"thought\")\n",
    "    return graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_graph(graph, initial_state: Dict[str, Any], max_steps: int = 50):\n",
    "    \"\"\"\n",
    "    Generic runner for the compiled graph.\n",
    "    - graph: result of build_graph(...). It must provide a `run_once(state)` or we emulate node execution.\n",
    "    If your StateGraph API differs, adapt accordingly.\n",
    "    \"\"\"\n",
    "    state = initial_state\n",
    "    step = 0\n",
    "\n",
    "    # Pretty print function\n",
    "    def print_new_history(prev_len):\n",
    "        history = state.get(\"history\", [])\n",
    "        for line in history[prev_len:]:\n",
    "            print(line)\n",
    "        return len(history)\n",
    "\n",
    "    prev_history_len = 0\n",
    "    while step < max_steps:\n",
    "        step += 1\n",
    "        state = node_thought_action(state)\n",
    "        prev_history_len = print_new_history(prev_history_len)\n",
    "\n",
    "        if state.get(\"is_complete\") or state.get(\"answer\"):\n",
    "            break\n",
    "\n",
    "        if state.get(\"last_action\"):\n",
    "            state = node_tool_execution(state)\n",
    "            prev_history_len = print_new_history(prev_history_len)\n",
    "            # continue loop, next iteration Thought will run again\n",
    "        else:\n",
    "            # if no action and not complete, allow loop to continue (LLM might set action next)\n",
    "            # small sleep to avoid busy loop in notebook (optional)\n",
    "            time.sleep(0.01)\n",
    "            continue\n",
    "\n",
    "    # final\n",
    "    print(\"\\n--- FINAL STATE ---\")\n",
    "    print(\"is_complete:\", state.get(\"is_complete\"))\n",
    "    print(\"parsed_declaration:\", state.get(\"parsed_declaration\"))\n",
    "    print(\"missing:\", state.get(\"missing\"))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {\n",
    "    \"question\": \"Bonjour, on m'a cambriolé ce matin, les voleurs sont passés par le vélux de la \"\n",
    "    \"chambre et ont volé tous les appareils électroniques. Merci de me contacter rapidement.\",\n",
    "    \"history\": [],\n",
    "    \"last_action\": None,\n",
    "    \"last_arguments\": None,\n",
    "    \"last_observation\": None,\n",
    "    \"is_complete\": False,\n",
    "    \"parsed_declaration\": None,\n",
    "    \"missing\": []\n",
    "}\n",
    "\n",
    "graph = build_graph(initial_state)\n",
    "\n",
    "final_state = run_graph(graph, initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
